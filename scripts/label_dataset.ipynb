{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ac241dd",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "680c7371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('..')\n",
    "from backend.services.crawler import crawl_all_sources\n",
    "from backend.services.classifier import classify_article\n",
    "from backend.services.embeddings import embed_text\n",
    "from backend.db.models import Article, Filter\n",
    "from backend.db.crud import add_filter\n",
    "from backend.services.filter import filter_article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc9e8b2",
   "metadata": {},
   "source": [
    "# Crawler\n",
    "Crawl latest articles from data sources defined in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1ba4d1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 110 articles to classify.\n"
     ]
    }
   ],
   "source": [
    "articles = crawl_all_sources()\n",
    "print(f\"Found {len(articles)} articles to classify.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa435516",
   "metadata": {},
   "source": [
    "# Classifier\n",
    "Classify articles extracted from crawling as relevant or irrelevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6386471b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for article in articles:\n",
    "    result = classify_article(article)\n",
    "    complete_result = {\n",
    "        \"article\": article,\n",
    "        \"classification\": result\n",
    "    }\n",
    "    results.append(complete_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "61d82e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28 relevant articles.\n"
     ]
    }
   ],
   "source": [
    "relevant_articles = [article for article in results if article['classification'].get('relevant')]\n",
    "print(f\"Found {len(relevant_articles)} relevant articles.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "83601a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provider of covert surveillance app spills passwords for 62,000 users\n"
     ]
    }
   ],
   "source": [
    "# Example of relevant article\n",
    "print(relevant_articles[2]['article']['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a98b302",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "Embed article summary that will be used as filter and upload to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9af35f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in results:\n",
    "    # Build object\n",
    "    relevant = article['classification'].get('relevant', False)\n",
    "    embedding = embed_text(article['classification']['summary'])\n",
    "    \n",
    "    filter_obj = Filter(\n",
    "        url=article['article']['id'],\n",
    "        embedding=embedding,\n",
    "        relevant=relevant\n",
    "    )\n",
    "    \n",
    "    # Upload to database\n",
    "    add_filter(filter_obj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b23495b",
   "metadata": {},
   "source": [
    "# Test filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d613a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../backend/tests/dummy_articles.json\", \"r\") as f:\n",
    "    dummy_articles = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7bc6654b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Critical Zero-Day Vulnerability Found in Windows Kernel',\n",
       " 'body': 'Microsoft has disclosed a zero-day vulnerability (CVE-2025-1234) in the Windows Kernel that allows privilege escalation. A patch is expected to be released in the next security update.',\n",
       " 'published_at': '2025-07-08T14:20:00Z',\n",
       " 'url': 'https://www.tomshardware.com/news/windows-kernel-zero-day',\n",
       " 'created_at': '2025-07-08T14:25:00Z',\n",
       " 'source': \"Tom's Hardware\",\n",
       " 'relevant': True}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_articles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3603ffbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article: Critical Zero-Day Vulnerability Found in Windows Kernel, Relevant: True, Ground Truth: True\n",
      "Article: Reddit User Shares Favorite Mechanical Keyboard of 2025, Relevant: False, Ground Truth: False\n",
      "Article: Outage Hits AWS US-East-1 Region, Affecting Major Services, Relevant: True, Ground Truth: True\n",
      "Article: Linux 6.8 Released with New Filesystem Features, Relevant: False, Ground Truth: False\n",
      "Article: Google Chrome Patches Critical V8 Vulnerability Exploited in the Wild, Relevant: True, Ground Truth: True\n",
      "Filtering accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "for article in dummy_articles:\n",
    "    # Create Article object\n",
    "    article_obj = Article(\n",
    "        title=article['title'],\n",
    "        body=article['body'],\n",
    "        url=article['url'],\n",
    "        source=article['source'],\n",
    "        published_at=article['published_at'],\n",
    "    )\n",
    "    \n",
    "    # Filter the article\n",
    "    relevant = filter_article(article_obj)\n",
    "    relevant_gt = article['relevant']\n",
    "    \n",
    "    print(f\"Article: {article['title']}, Relevant: {relevant}, Ground Truth: {relevant_gt}\")\n",
    "    \n",
    "    score.append(relevant == relevant_gt)\n",
    "\n",
    "print(f\"Filtering accuracy: {np.mean(score)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
